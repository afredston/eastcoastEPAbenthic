---
title: "Data Prep"
output: html_notebook
---

Starting with a clean environment:
```{r}
rm(list=ls())
```


```{r}
library("tidyverse")
library("here")
library("taxize") #for standardizing taxonomy - but so far I haven't needed this since all old taxons matched with corrections provided in the 2010 dataset
#remotes::install_github("ropensci/rfishbase")
library("rfishbase")
library("dplyr")
library("stringi")
library("lubridate") #for working with dates
```

Downloaded all benthic macroinvertebrate files from EPA. Had to also download site info files for some.
```{r}
BC2000<-read_csv(here("current work", "raw data", "nca_benthicdata.csv")) #data w species counts early 2000's
BC2010a<-read_csv(here("current work", "raw data", "assessed_ncca2010_benthic_data.csv")) #data w species counts 2010 (used in water quality assessments)
BC2010b<-read_csv(here("current work", "raw data", "not_assessed_ncca2010_benthic_data.csv")) #data w species counts 2010 (not used in water quality assessments) *ALL FROM VISIT 2 so ignore
BC2010asites<-read_csv(here("current work", "raw data", "assessed_ncca2010_siteinfo.revised.06212016.csv")) #site info 2010 (used in water quality assessments)
BC2010bsites<-read_csv(here("current work", "raw data", "not_assessed_ncca2010_siteinfo.revised.06212016.csv")) #site info 2010 (not used in water quality assessments) *ALL FROM VISIT 2 so ignore
BG2010<-read_csv(here("current work", "raw data", "ncca2010_benthic_indicator_status.csv")) #data w necessary info on grabs
BG2015<-read_csv(here("current work", "raw data", "ncca_2015_benthic_grab_estuarine-data.csv")) #data on the just the grabs 2015
BC2015<-read_csv(here("current work", "raw data", "ncca_2015_benthic_count_estuarine-data.csv")) #data w species counts 2015
BC2015sites<-read_csv(here("current work", "raw data", "ncca_2015_site_information_estuarine-data.csv")) #data w site info 2015
BG2020<-read_csv(here("current work", "raw data", "ncca20_bentgrab_data.csv")) #data on just the grabs 2020
BC2020<-read_csv(here("current work", "raw data", "ncca20_bentcount_data.csv")) #data w species counts 2020
BC2020Esites<-read_csv(here("current work", "raw data", "ncca20_siteinfo_estuaries_data_2.csv")) # estuary site info 2020
BC2020Rsites<-read_csv(here("current work", "raw data", "ncca20_siteinfo_reef_flats_data.csv")) #reef flat site info 2020

#missing coordinates data for 2015
#BG2015
#BC2015
```

# Step 1: Cut data so only considering east coast marine estuaries 
Using the buoy marking the southern most extent of Florida located at 24.469833 N, -80.20817 E and selecting only observations made NE of it to get only east coast observations.
```{r}
BC2000<-BC2000 %>%
  filter(LON_DD > -80.20817 & LAT_DD > 24.469833) %>% #note: this filter alone will give all of the east coast observations since there are no other observations NE of this point
  filter(NCA_REGION == "East_Coast") # but can ensure by adding this
#BC2000

BC2010a<-merge(BC2010a, BC2010asites, by = "UID") #merging these two data frames so can get the coordinates of each grab sample since these aren't in the count data
BC2010a<-BC2010a %>%
  filter(ALON_DD > -80.20817 & ALAT_DD > 24.469833) %>%
  filter(NCA_REGION == "East Coast") #to remove Great Lakes samples located NE of this point
#BC2010a

BC2010b<-merge(BC2010b, BC2010bsites, by = "UID")
BC2010b<-BC2010b %>%
  filter(TLON_DD > -80.20817 & TLAT_DD > 24.469833) %>% 
  filter(NCA_REGION == "East Coast") #to remove Great Lakes samples located NE of this point and any from Hawaii
#BC2010b

#Also need grab area data so we can calculate species densities
ga<-BG2015 %>% select(UID, FINAL_GRAB_AREA) 
BC2015<-merge(BC2015, ga, by="UID")
coords<-BC2015sites %>% select(UID, LON_DD, LAT_DD, NCA_REG) # get coordinates for each site and region info from the 2010 data
BC2015<-merge(BC2015, coords, by="UID")
BC2015 %>%
  filter(LON_DD > -80.20817 & LAT_DD > 24.469833) %>% #note: this filter alone will give all of the east coast observations since there are no other observations NE of this point
  filter(NCA_REG == "East_Coast") # but can ensure by adding this
#BC2015


BC2020 %>% filter(HABITAT == "EST")
coords<-BC2020Esites %>% select(UID, LON_DD, LAT_DD, NCA_REG) # get coordinates for each site and region info from the 2020 estuary data
BC2020<-merge(BC2020, coords, by = "UID")
BC2020 %>%
  filter(LON_DD > -80.20817 & LAT_DD > 24.469833) %>% #note: this filter alone will give all of the east coast observations since there are no other observations NE of this point
  filter(NCA_REG == "East_Coast") # but can ensure by adding this
#BC2020
```

# Step 2: Match up taxonomy of early 2000's with 2010 data. Then match up taxonomy to data in sealifbase.
```{r}
BC2000x<-BC2000 %>% mutate(TAXON_ORIGINAL = taxon) #create column to match up the original taxon names in the 2000s data to the original taxon names in the 2010 data
txn_cors<-BC2010a %>%
  select("TAXON_ORIGINAL", "TAXON_CORRECTED", "WORMS_APHIAID") #taxonomic corrections applied to 2010 data
BC2000cor<-merge(BC2000x, txn_cors, by="TAXON_ORIGINAL") #matching up the corrections applied to the 2010 data to the 2000s data
#CHECK out the corrections that were applied:
#BC2000cor %>% select("TAXON_ORIGINAL", "taxon", "TAXON_CORRECTED", "WORMS_APHIAID") %>%
#  filter(taxon != TAXON_CORRECTED)
```


# Step 3: extracting and calculating the common data columns of interest to us and assembling one complete dataset to work with.
```{r}
#DATA we care about:
BC2000cor #columns we care about: 
#A) SITE_ID 
#B) tot_num_m2
#C) LON_DD 
#D) LAT_DD 
#E) SAMPYEAR 
#F) WORMS_APHIAID 
BC2000cor.sub<-BC2000cor %>% select(SITE_ID, tot_num_m2, LON_DD, LAT_DD, SAMPYEAR, WORMS_APHIAID)

BC2010a #coloumns we care about: 
#A) SITE_ID = SITE_ID.x 
#B) tot_num_m2 = TOTAL/Final_Grab_Area(m2)
#C) LON_DD = ALON_DD
#D) LAT_DD = ALAT_DD
#E) SAMPYEAR = 2010
#F) WORMS_APHIAID
#G) ***MAP_DATUM*** use this for mapping all the data as this should be consistent for all the data
#H) ***VISIT_NO*** need to decide whether to use repeat visits or not -> filter for 1st visit
BC2010a<-BC2010a %>% filter(VISIT_NO == 1)
colnames(BC2010a)<-c(colnames(BC2010a[,1:34]), "FINAL_GRAB_AREA_m2", colnames(BC2010a[,36:length(colnames(BC2010a))]))
BC2010a.sub<-BC2010a %>% mutate(SITE_ID = SITE_ID.x,
                   tot_num_m2 = TOTAL/FINAL_GRAB_AREA_m2,
                   LON_DD = ALON_DD,
                   LAT_DD = ALAT_DD,
                   SAMPYEAR = 2010) %>%
  select(SITE_ID, tot_num_m2, LON_DD, LAT_DD, SAMPYEAR, WORMS_APHIAID)

#BC2010b
#A) SITE_ID = SITE_ID.x
#B) tot_num_m2 = TOTAL/Final_Grab_Area(m2)
#C) LON_DD = TLON_DD
#D) LAT_DD = TLAT_DD
#E) SAMPYEAR = year(as.Date(DATE_COL.x))
#F) WORMS_APHAID
#H) ***VISIT_NO.y*** need to decide whether to use repeat visits or not -> filter for 1st visit
#BC2010b<-BC2010b %>% filter(VISIT_NO.x == 1) # *ALL FROM VISIT 2 so ignore


BC2015
#A) SITE_ID
#B) tot_num_m2 = TOTAL/ ***need area of grabs for this data***
#C) LON_DD
#D) LAT_DD
#E) SAMPYEAR = YEAR
#F) WORMS_APHAID = APHIA_ID
#H) ***VISIT_NO*** need to decide whether to use repeat visits or not -> filter for 1st visit
BC2015<-BC2015 %>% filter(VISIT_NO == 1)
BC2015.sub<-BC2015 %>% mutate(tot_num_m2 = TOTAL/as.numeric(FINAL_GRAB_AREA),
                   SAMPYEAR = YEAR,
                   WORMS_APHIAID = APHIA_ID) %>%
  select(SITE_ID, tot_num_m2, LON_DD, LAT_DD, SAMPYEAR, WORMS_APHIAID)

BC2020
#A) SITE_ID
#B) tot_num_m2 = DENSITY
#C) LON_DD 
#D) LAT_DD
#E) SAMPYEAR = 2020
#F) WORMS_APHAID = APHIA_ID
#H) ***VISIT_NO*** need to decide whether to use repeat visits or not -> filter for 1st visit
BC2020<-BC2020 %>% filter(VISIT_NO == 1)
BC2020.sub<-BC2020 %>% mutate(tot_num_m2 = DENSITY,
                   SAMPYEAR = 2020, 
                   WORMS_APHIAID = APHIA_ID) %>%
  select(SITE_ID, tot_num_m2, LON_DD, LAT_DD, SAMPYEAR, WORMS_APHIAID)

all.data<-rbind(BC2000cor.sub, BC2010a.sub, BC2015.sub, BC2020.sub)
all.data
```






```{r}
# ********TRYING TO MATCH UP SPECIES IN THE EARLY 2000s DATA WITH EITHER WORMS OR SEALIFEBASE!!! NOT WORKING!!!************
BC2000cor %>% select(TAXON_CORRECTED, WORMS_APHIAID) %>% unique() #to look at corrected names and their supposed AphiaIDs in WoRMS
BC2000cor %>% select(TAXON_CORRECTED) %>% unique() %>% validate_names() #trying to match sealifebase gives us nothing!!!
validate_names("Acanthohaustorius intermedius") #trying name by name I'm getting nothing either....
# searching this species name directly in sealifebase.org's online portal I get a result though...
wormsIDs2000<-BC2000cor %>% select(WORMS_APHIAID) %>% unique() #extracting the IDs...
wormsIDs2000
worms_downstream(id=wormsIDs2000[,1], downto="species") #...and searching for them in WoRMS also is giving me nothing
```


```{r}
fb_tbl("species", "sealifebase")
```




